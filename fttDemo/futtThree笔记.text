//旋转的方块代码
<script>
	var scene = new THREE.Scene();
	var camera = new THREE.PerspectiveCamera(75,window.innerWidth/window.innerHeight,0.1,1000);
	var renderer = new THREE.WebGLRenderer();
	
	var geometry = new THREE.CubeGeometry(1,1,1);
	var material = new THREE.MeshBasicMaterial({color:0x00ff00});
	//设置物体,在three.js中，我们使用Mesh模型，Mesh的构造函数是这样的：Mesh( geometry, material ) geometry是它的形状，material是它的材质。 三维模型通常用三角形的网格来描述
	var cube =  new THREE.Mesh(geometry,material);    
	scene.add(cube);
	
	camera.position.z = 5;
	
	renderer.setSize(window.innerWidth,window.innerHeight);
	//将渲染器的元素添加到页面中
	document.body.appendChild(renderer.domElement);
	renderer.render(scene,camera); 

    // 方块动起来
	// function render(){
	// 	requestAnimationFrame(render);  //请求动画帧:与setTimeout相比，requestAnimationFrame最大的优势是由系统来决定回调函数的执行时机。具体一点讲，如果屏幕刷新率是60Hz,那么回调函数就每16.7ms被执行一次，如果刷新率是75Hz，那么这个时间间隔就变成了1000/75=13.3ms，换句话说就是，requestAnimationFrame的步伐跟着系统的刷新步伐走。它能保证回调函数在屏幕每一次的刷新间隔中只被执行一次，这样就不会引起丢帧现象，也不会导致动画出现卡顿的问题。
	// 	cube.rotation.x += 0.1;
	// 	cube.rotation.y += 0.1;
	// 	renderer.render(scene,camera);(方块动起来删除方面的相同的代码)
	// }
	// render();
</script>


	
Three.js
三个组件：场景（scene）、相机（camera）和渲染器（renderer）
记住关建语句：有了这三样东西，我们才能够使用相机将场景渲染到网页上去。（注意是使用相机将场景转染到网页上）

创建这三要素的代码如下：
var scene = new THREE.Scene();  // 场景
var camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);// 透视相机
var renderer = new THREE.WebGLRenderer();   // 渲染器
renderer.setSize(window.innerWidth, window.innerHeight);    // 设置渲染器的大小为窗口的内宽度，也就是内容区的宽度
document.body.appendChild(renderer.domElement);

场景
在Threejs中场景就只有一种，用THREE.Scene来表示，要构件一个场景也很简单，只要new一个对象就可以了，代码如下：
var scene = new THREE.Scene();
场景是所有物体的容器，如果要显示一个苹果，就需要将苹果对象加入场景中。


相机
另一个组建是相机，相机决定了场景中那个角度的景色会显示出来。相机就像人的眼睛一样，人站在不同位置，抬头或者低头都能够看到不同的景色。
场景只有一种，但是相机却又很多种。和现实中一样，不同的相机确定了呈相的各个方面。
比如有的相机适合人像，有的相机适合风景，专业的摄影师根据实际用途不一样，选择不同的相机。对程序员来说，只要设置不同的相机参数，就能够让相机产生不一样的效果。
在Threejs中有多种相机，这里介绍一种：
透视相机（THREE.PerspectiveCamera）
这里我们使用一个透视相机，透视相机的参数很多，这里先不详细讲解。后面关于相机的那一章，我们会花大力气来讲。定义一个相机的代码如下所示：（已经迫不及待想看看相机的参数了，点这里）
var camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
//fov，aspect，near，far(4个参数)：
fov表示摄像机视锥体垂直视野角度，最小值为0，最大值为180，默认值为50，实际项目中一般都定义45，因为45最接近人正常睁眼角度；
aspect表示摄像机视锥体长宽比，默认长宽比为1，即表示看到的是正方形，实际项目中使用的是屏幕的宽高比；
near表示摄像机视锥体近端面，这个值默认为0.1，实际项目中都会设置为1；
far表示摄像机视锥体远端面，默认为2000，这个值可以是无限的，说的简单点就是我们视觉所能看到的最远距离。
透视投影相机的位置和position，up，lookAt有关系。
position用来指定相机在三维坐标中的位置，
up用来指定相机拍摄时相机头顶的方向，
lookAt表示相机拍摄时指向的中心点。具体的设置如下代码：
// 统一设置position中xyz坐标
camera.position.set(0,0,0);

 // 单独设置position中特定坐标
 camera.position.x = 0;
 camera.position.y = 0;
 camera.position.z = 0;
 
 // 统一设置up中xyz坐标
 camera.up.set(0,1,0);
 
// 单独设置up中特定坐标（哪个轴为上方，意思就是说坐标的方向）
 camera.up.x = 0;
 camera.up.y = 1;
 camera.up.z = 0;

 // lookAt设置必须统一设置
 camera.lookAt({
    x:0,
    y:0,
    z:0
});


 
渲染器
最后一步就是设置渲染器，渲染器决定了渲染的结果应该画在页面的什么元素上面，并且以怎样的方式来绘制。这里我们定义了一个WebRenderer渲染器，代码如下所示：
var renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);
注意，渲染器renderer的domElement元素，表示渲染器中的画布，所有的渲染都是画在domElement上的，
所以这里的appendChild表示将这个domElement挂接在body下面，这样渲染的结果就能够在页面中显示了。

添加物体到场景中
var geometry = new THREE.CubeGeometry(1,1,1); 
var material = new THREE.MeshBasicMaterial({color: 0x00ff00});
var cube = new THREE.Mesh(geometry, material); 
scene.add(cube);

THREE.CubeGeometry：他是一个几何体
CubeGeometry(width, height, depth, segmentsWidth, segmentsHeight, segmentsDepth, materials, sides)
width：立方体x轴的长度
height：立方体y轴的长度
depth：立方体z轴的深度，也就是长度


渲染（渲染不是渲染器，一个是实物，一个是动作）
使用渲染器，结合相机和场景来得到结果画面。实现这个功能的函数是：
renderer.render(scene, camera);
渲染函数的原型：
render( scene, camera, renderTarget, forceClear )
scene：前面定义的场景
camera：前面定义的相机
renderTarget：渲染的目标，默认是渲染到前面定义的render变量中
forceClear：每次绘制之前都将画布的内容给清除，即使自动清除标志autoClear为false，也会清除。

渲染循环
渲染有两种方式：实时渲染和离线渲染 。
离线渲染：事先渲染好一帧一帧的图片，然后再把图片拼接成电影的。
实时渲染：就是需要不停的对画面进行渲染，即使画面中什么也没有改变，也需要重新渲染。下面就是一个渲染循环：
function render() {
    cube.rotation.x += 0.1;
    cube.rotation.y += 0.1;
    renderer.render(scene, camera);
    requestAnimationFrame(render);
}
其中一个重要的函数是requestAnimationFrame，这个函数就是让浏览器去执行一次参数中的函数，这样通过上面render中调用requestAnimationFrame()函数，requestAnimationFrame()函数又让rander()再执行一次，就形成了我们通常所说的游戏循环了。

场景，相机，渲染器之间的关系：
Three.js中的场景是一个物体的容器，开发者可以将需要的角色放入场景中，例如苹果，葡萄。同时，角色自身也管理着其在场景中的位置。
相机的作用就是面对场景，在场景中取一个合适的景，把它拍下来。
渲染器的作用就是将相机拍摄下来的图片，放到浏览器中去显示。
（物体是直接放在场景中的，渲染器：结合相机和场景得到画面，还要放到浏览器中）








向量
THREE.Vector3 = function ( x, y, z ) {
this.x = x || 0;
this.y = y || 0;
this.z = z || 0;
};

//Threejs 中定义一个点
（THREE.Vector3D）
假设有一个点x=4，y=8，z=9。你可以这样定义它：
var point1 = new THREE.Vecotr3(4,8,9);
另外你也可以使用set方法，代码如下：
var point1 = new THREE.Vector3();
point1.set(4,8,9);


画一条彩色线：这是一条每个点不同颜色的线条(test1.js)




//线条的深入理解
在Threejs中，一条线由点，材质和颜色组成。
点由THREE.Vector3表示，Threejs中没有提供单独画点的函数，它必须被放到一个THREE.Geometry形状中，
这个结构中包含一个数组vertices，这个vertices就是存放无数的点（THREE.Vector3）的数组。
为了绘制一条直线，首先我们需要定义两个点，如下代码所示：
var p1 = new THREE.Vector3( -100, 0, 100 );
var p2 = new THREE.Vector3(  100, 0, -100 );
声明一个THREE.Geometry，并把点加进入
var geometry = new THREE.Geometry();
geometry.vertices.push(p1);
geometry.vertices.push(p2);

geometry.vertices的能够使用push方法，是因为geometry.vertices是一个数组。这样geometry 中就有了2个点了。
然后我们需要给线加一种材质，可以使用专为线准备的材质，THREE.LineBasicMaterial。
最终我们通过THREE.Line绘制了一条线:
var line = new THREE.Line( geometry, material, THREE.LinePieces);


画高中时深爱的坐标平面(test2.js)
Three单位 
// 1个单位（一般为1米）对应屏幕多少像素（z轴为向上的情况）
// new THREE.PerspectiveCamera(45,w/h,1,1000)，屏幕分辨率560*600为例（canvas宽高）
45：视角，指定视景体的视野的角度，以度数为单位，y轴的上下方向（x轴的视角可以由y轴视角和视景体的宽高比计算出）
w/h：视景体的宽高比(窗口的纵横比,即x/y)
1：指定观察者到视景体的最近的裁剪面的距离（必须为正数）
1000：指定观察者到视景体的最远的裁剪面的距离（必须为正数）

y轴不为0
//camera.position.y = 150;
//2*tan(22.5) = 2* 0.414213562373 = 0.82842
// 计算屏幕近景裁剪面的高 h = 2*tan(22.5)*150 = 0.82842 * 150 = 124.263  
//  600/ (2*tan(22.5)*(ZNear+z)) (ZNear是第三个参数,例子为1,z:150-1)
//1单位 = 600 /  124.263   = 4.82px

y轴为0时（要按第三个数值计算）
(ZNear+z)：= 1
1单位 = 600/0.82842


new THREE.Line()
position.x 是中间的点的位置（平行y轴移动到不同位置）



//让场景动起来
第一种方法是让物体在坐标系里面移动，摄像机不动。第二种方法是让摄像机在坐标系里面移动，物体不动。
//渲染循环
物体运动还有一个关键点，就是要渲染物体运动的每一个过程，让它显示给观众。渲染的时候，我们调用的是渲染器的render() 函数。代码如下：
renderer.render( scene, camera );
如果我们改变了物体的位置或者颜色之类的属性，就必须重新调用render()函数，才能够将新的场景绘制到浏览器中去。不然浏览器是不会自动刷新场景的。
如果不断的改变物体的颜色，那么就需要不断的绘制新的场景，所以我们最好的方式，是让画面执行一个循环，不断的调用render来重绘，这个循环就是渲染循环，在游戏中，也叫游戏循环。
为了实现循环，我们需要javascript的一个特殊函数，这个函数是requestAnimationFrame。
调用requestAnimationFrame函数，传递一个callback参数，则在下一个动画帧时，会调用callback这个函数。

代码：
function animate() {
    render();
    requestAnimationFrame( animate );
}


//改变相机的位置，让物体移动(test3.js)

创建一个虚拟的球形网格 Mesh 的辅助对象来模拟 点光源 PointLight.
PointLight(color,intensity,distance,position,visible);
ps：光线的亮度不会随着距离的增加而减弱（so:越大说明圆柱照到的光面积越广,由于光线的亮度不会随着距离的增加而减弱.所以看起来越亮）
光源的 distance 属性决定了在光线强度变为 0 之前光线的传播距离。默认为 0，表示光线强度不会随着距离的增加而减弱。
这里我们接着把 distance 属性设为 22，表示光线在距离为22的地方慢慢地减少为 0。


PointLightHelper( light : PointLight, sphereSize : Float, color : Hex )
light – 要模拟的光源.
sphereSize – (可选的) 球形辅助对象的尺寸. 默认为 1.
color – (可选的) 如果没有赋值辅助对象将使用光源的颜色.


//使用动画引擎Tween.js来创建动画
通过移动相机和移动物体来产生动画的效果。使用的方法是在渲染循环里去移动相机或者物体的位置。如果动画稍微复杂一些，这种方式实现起来就比较麻烦一些了。
动画引擎来实现动画效果
function initTween()
{
    new TWEEN.Tween(mesh.position).to( { x: -400 }, 3000 ).repeat( Infinity ).start();
}
TWEEN.Tween的构造函数接受的是要改变属性的对象，这里传入的是mesh的位置。Tween的任何一个函数返回的都是自身，所以可以用串联的方式直接调用各个函数。
to函数，接受两个参数，第一个参数是一个集合，里面存放的键值对，键x表示mesh.position的x属性，值-400表示，动画结束的时候需要移动到的位置。第二个参数，是完成动画需要的时间，这里是3000ms。
repeat( Infinity )表示重复无穷次，也可以接受一个整形数值，例如5次。
Start表示开始动画，默认情况下是匀速的将mesh.position.x移动到-400的位置。

第三步是，需要在渲染函数中去不断的更新Tween，这样才能够让mesh.position.x移动位置:

function initTween(){
    new TWEEN.Tween(mesh.position).to( { x: 400 }, 1000 ).repeat(Infinity).start();
}

function threeStart(){
	initTween();
	animation();
}

function animation()
{
    renderer.render(scene, camera);
    requestAnimationFrame(animation);
    TWEEN.update();
}


//三维空间的观察（主讲相机）test4.js
单反、双反：THREE.Camera
两种子类：分别是正投影相机THREE.OrthographicCamera和透视投影相机THREE.PerspectiveCamera
正投影和透视投影的区别是：
	透视投影有一个基本点，就是远处的物体比近处的物体小。我们看看著名的蒙娜丽莎的微笑就是典型的透视作品：
在工程建筑领域，正投影的例子很多，其特点是，远近高低比例都相同（比如画尺寸图）；

正投影相机：
OrthographicCamera( left, right, top, bottom, near, far )
有了这些参数和相机中心点，我们这里将相机的中心点又定义为相机的位置。
通过这些参数，我们就能够在三维空间中唯一的确定上图的一个长方体。这个长方体也叫做视景体。
投影变换的目的就是定义一个视景体，使得视景体外多余的部分裁剪掉，最终图像只是视景体内的有关部分。
例子：
var camera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
scene.add( camera );
这个例子将浏览器窗口的宽度和高度作为了视景体的高度和宽度，相机正好在窗口的中心点上。这也是我们一般的设置方法，基本上为了方便，我们不会设置其他的值。

透视投影相机：透视投影是更符合我们视觉的投影，当你凝视一个人时，就是因为远近高低各不同。
PerspectiveCamera( fov, aspect, near, far )
1、视角fov：这个最难理解,我的理解是,眼睛睁开的角度,即,视角的大小,如果设置为0,相当你闭上眼睛了,所以什么也看不到,如果为180,那么可以认为你的视界很广阔,但是在180度的时候，往往物体很小，因为他在你的整个可视区域中的比例变小了。
2、近平面near：这个呢，表示你近处的裁面的距离。补充一下，也可以认为是眼睛距离近处的距离，请不要设置为负值，Three.js就傻了,不知道怎么算了,
3、远平面far：这个呢，表示你远处的裁面,
4、纵横比aspect：实际窗口的纵横比，即宽度除以高度。这个值越大，说明你宽度越大，那么你可能看的是宽银幕电影了，如果这个值小于1，那么可能你看到的是LED屏幕了。


五彩的光源
光源基类:THREE.Light ( hex )

由基类派生出来的其他种类光源:

环境光:THREE.AmbientLight( hex )
境光是经过多次反射而来的光称为环境光，无法确定其最初的方向。环境光是一种无处不在的光。环境光源放出的光线被认为来自任何方向。因此，当你仅为场景指定环境光时，所有的物体无论法向量如何，都将表现为同样的明暗程度。 （这是因为，反射光可以从各个方向进入您的眼睛）

点光源:PointLight( color, intensity, distance )
Color：光的颜色
Intensity：光的强度，默认是1.0,就是说是100%强度的灯光，
distance：光的距离，从光源所在的位置，经过distance这段距离之后，光的强度将从Intensity衰减为0。 默认情况下，这个值为0.0，表示光源强度不衰减。

聚光灯:THREE.SpotLight( hex, intensity, distance, angle, exponent )
这种光源的光线从一个锥体中射出，在被照射的物体上产生聚光的效果。使用这种光源需要指定光的射出方向以及锥体的顶角α。(打光那种)
Hex：聚光灯发出的颜色，如0xFFFFFF
Intensity：光源的强度，默认是1.0，如果为0.5，则强度是一半，意思是颜色会淡一些。和上面点光源一样。
Distance：光线的强度，从最大值衰减到0，需要的距离。 默认为0，表示光不衰减，如果非0，则表示从光源的位置到Distance的距离，光都在线性衰减。到离光源距离Distance时，光源强度为0.
Angle：聚光灯着色的角度，用弧度作为单位，这个角度是和光源的方向形成的角度。
exponent：光源模型中，衰减的一个参数，越大衰减约快。

！！！！！！当没有任何光源的时候，最终的颜色将是黑色，无论材质是什么颜色。（通俗点就是说，即使你传了5五颜六色的衣服，在没有光的世界里，就等于是黑色）

兰伯特材质：
在灰暗的或不光滑的表面产生均匀散射而形成的材质类型。
比如一张纸就是Lambert表面。 
首先它粗糙不均匀，不会产生镜面效果。
我们在阅读书籍的时候，没有发现书上一处亮，一处不亮吧，它非常均匀，这就是兰伯特材质。

好了，我们来分析一下这段代码。

1、 在A处，我们设置了一个红色的环境光，并把它放在了一个位置上。
2、 在B处，我们使用了淡红色的兰伯特材质。
最后整个效果中，长方体呈现的是两个颜色之和。我们要说的是，长方体显示棕色，是因为长方体反射了红色的光，长方体本身的颜色是0x880000，光源的颜色是0xFF0000，红色的光照在物体上，物体反射了红色的光，所以呈现相交色。
我们现在一直在使用环境光，从环境光的构造函数来看，它只有颜色，其位置对场景中的物体并没有影响，因为他是均匀的反射到物体的表面的。

方向光（平行光）：THREE.DirectionalLight = function ( hex, intensity )（test5.js）
其参数如下：
Hex：关系的颜色，用16进制表示
Intensity：光线的强度，默认为1。因为RGB的三个值均在0~255之间，不能反映出光照的强度变化，光照越强，物体表面就更明亮。它的取值范围是0到1。如果为0，表示光线基本没什么作用，那么物体就会显示为黑色。
方向由位置和原点（0,0,0）来决定，方向光只与方向有关，与离物体的远近无关。
分别将平行光放到（0,0,100），（0,0,50），（0,0,25），（0,0,1），渲染的结果还是红色和黑色，颜色的深浅不与离物体的距离相关。


环境光和方向光：一起作用
方向光方向由环境光和方向光共同作用而成的，其实是两种光源颜色的简单相加
没有被方向光照射到的：则是单纯的环境光



第6章 纹理，不一样的皮肤（test6.js）
纹理由图片组成
纹理类由THREE.Texture表示，其构造函数如下所示：
THREE.Texture( image, mapping, wrapS, wrapT, magFilter,minFilter, format, type, anisotropy )
各个参数的意义是：
Image：这是一个图片类型，基本上它有ImageUtils来加载，代码：
// url 是一个http://xxxx/aaa.jpg 的类似地址，javascript没有从本地加载数据的能力，
// 所以没有办法从您电脑的C盘加载数据。
var image = THREE.ImageUtils.loadTexture(url);   
Mapping：是一个THREE.UVMapping()类型，它表示的是纹理坐标。下一节，我们将说说纹理坐标。
wrapS：表示x轴的纹理的回环方式，就是当纹理的宽度小于需要贴图的平面的宽度的时候，平面剩下的部分应该p以何种方式贴图的问题。
wrapT：表示y轴的纹理回环方式。 
magFilter和minFilter表示过滤的方式，这是OpenGL的基本概念，我将在下面讲一下，目前你不用担心它的使用。当您不设置的时候，它会取默认值，所以，我们这里暂时不理睬他。
format：表示加载的图片的格式，这个参数可以取值THREE.RGBAFormat，RGBFormat等。THREE.RGBAFormat表示每个像素点要使用四个分量表示，分别是红、绿、蓝、透明来表示。RGBFormat则不使用透明，也就是说纹理不会有透明的效果。
type：表示存储纹理的内存的每一个字节的格式，是有符号，还是没有符号，是整形，还是浮点型。不过这里默认是无符号型（THREE.UnsignedByteType）。暂时就解释到这里，有需要时，我们在仔细分析，或者给作者留言询问。
anisotropy：各向异性过滤。使用各向异性过滤能够使纹理的效果更好，但是会消耗更多的内存、CPU、GPU时间，暂时就了解到这里吧。

纹理坐标：（四个角的坐标，左下角为（0，0））
当我们用一幅图来做纹理的时候，那么这幅图就隐示的被赋予了如图一样的纹理坐标，这个纹理坐标将被对应到一个形状上。

画一个平面
var geometry = new THREE.PlaneGeometry( 500, 300, 1, 1 );
为平面赋予纹理坐标
geometry.vertices[0].uv = new THREE.Vector2(0,0);
geometry.vertices[1].uv = new THREE.Vector2(1,0);
geometry.vertices[2].uv = new THREE.Vector2(1,1);
geometry.vertices[3].uv = new THREE.Vector2(0,1);
加载纹理